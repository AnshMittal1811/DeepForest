

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Configuration File &mdash; DeepForest 0.1.4 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="deepforest package" href="source/deepforest.html" />
    <link rel="prev" title="Training New Models" href="training.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> DeepForest
          

          
          </a>

          
            
            
              <div class="version">
                0.1.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="landing.html">What is DeepForest?</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Training New Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Configuration File</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sample-deepforest-config-yml">Sample deepforest_config.yml</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-parameters">Training parameters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#batch-size-1">batch_size: 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#weights-none">weights: None</a></li>
<li class="toctree-l3"><a class="reference internal" href="#backbone-resnet50">backbone: resnet50</a></li>
<li class="toctree-l3"><a class="reference internal" href="#image-min-side-800">image-min-side: 800</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multi-gpu-1">multi-gpu: 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#epochs-1">epochs: 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#freeze-layers-0">freeze_layers: 0</a></li>
<li class="toctree-l3"><a class="reference internal" href="#freeze-resnet-false">freeze_resnet: False</a></li>
<li class="toctree-l3"><a class="reference internal" href="#score-threshold-0-05">score_threshold: 0.05</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#keras-fit-generator-methods">Keras fit_generator methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multiprocessing-false">multiprocessing: False</a></li>
<li class="toctree-l3"><a class="reference internal" href="#workers-1">workers: 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#max-queue-size-10">max_queue_size: 10</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-transform-true">random_transform: True</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#validation">Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#validation-annotations-none">validation_annotations: None</a></li>
<li class="toctree-l3"><a class="reference internal" href="#save-snapshot-false">save-snapshot: False</a></li>
<li class="toctree-l3"><a class="reference internal" href="#save-path-snapshots">save_path: snapshots/</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snapshot-path-snapshots">snapshot_path: snapshots/</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/deepforest.html">deepforest package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DeepForest</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Configuration File</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/training_config.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="configuration-file">
<h1>Configuration File<a class="headerlink" href="#configuration-file" title="Permalink to this headline">¶</a></h1>
<p>For ease of experimentation, DeepForest reads the majority of training parameters from a .yml file. This allows a user to quickly survey and change the training settings without needing to dive into the source code. Deep learning models are complex, and DeepForest tries to set reasonable defaults when possible. To get the best performance, some parameter exploration will be required for most novel applications. To track  Experiments can be tracked using a <a class="reference external" href="comet.ml">comet_ml</a> dashboard.</p>
<div class="section" id="sample-deepforest-config-yml">
<h2>Sample deepforest_config.yml<a class="headerlink" href="#sample-deepforest-config-yml" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># Config file for DeepForest module</span>
<span class="c1">###</span>

<span class="c1">### Training</span>
<span class="c1">### Batch size. If multi-gpu is &gt; 1, this is the total number of images per batch across all GPUs. Must be evenly divisible by multi-gpu.</span>
<span class="n">batch_size</span><span class="p">:</span> <span class="mi">1</span>
<span class="c1">### Model weights to load before training. From keras.model.save()</span>
<span class="n">weights</span><span class="p">:</span> <span class="kc">None</span>
<span class="c1">### Retinanet backbone. See the keras-retinanet repo for options. Only resnet50 has been well explored.</span>
<span class="n">backbone</span><span class="p">:</span> <span class="n">resnet50</span>
<span class="c1">### Resize images to min size. Retinanet anchors may need to be remade if signficantly reducing image size.</span>
<span class="n">image</span><span class="o">-</span><span class="nb">min</span><span class="o">-</span><span class="n">side</span><span class="p">:</span> <span class="mi">800</span>
<span class="c1">##Number of GPUs to train</span>
<span class="n">multi</span><span class="o">-</span><span class="n">gpu</span><span class="p">:</span> <span class="mi">1</span>
<span class="c1">#Number of full cycles of the input data to train</span>
<span class="n">epochs</span><span class="p">:</span> <span class="mi">1</span>
<span class="c1">#Validation annotations. If training using fit_generator, these will be evaluated as a callback at the end of each epoch.</span>
<span class="n">validation_annotations</span><span class="p">:</span> <span class="kc">None</span>
<span class="c1">###Freeze layers. Used for model finetuning, freeze the bottom n layers.</span>
<span class="n">freeze_layers</span><span class="p">:</span> <span class="mi">0</span>
<span class="c1">###Freeze resnet backbone entirely.</span>
<span class="n">freeze_resnet</span><span class="p">:</span> <span class="kc">False</span>

<span class="c1">###Evaluation</span>
<span class="c1">###Score threshold, above which bounding boxes are included in evaluation predictions</span>
<span class="n">score_threshold</span><span class="p">:</span> <span class="mf">0.05</span>

<span class="c1">#Keras fit_generator methods, these do not apply to tfrecords input_type</span>
<span class="n">multiprocessing</span><span class="p">:</span> <span class="kc">False</span>
<span class="n">workers</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">max_queue_size</span><span class="p">:</span> <span class="mi">10</span>
<span class="n">random_transform</span><span class="p">:</span> <span class="kc">True</span>

<span class="c1">#save snapshot and images</span>
<span class="c1">###Whether to save snapshots at the end of each epoch</span>
<span class="n">save</span><span class="o">-</span><span class="n">snapshot</span><span class="p">:</span> <span class="kc">False</span>
<span class="c1">#Save directory for images and snapshots</span>
<span class="n">save_path</span><span class="p">:</span> <span class="n">snapshots</span><span class="o">/</span>
<span class="n">snapshot_path</span><span class="p">:</span> <span class="n">snapshots</span><span class="o">/</span>
</pre></div>
</div>
</div>
<div class="section" id="training-parameters">
<h2>Training parameters<a class="headerlink" href="#training-parameters" title="Permalink to this headline">¶</a></h2>
<p>These parameters effect training specifications.</p>
<div class="section" id="batch-size-1">
<h3>batch_size: 1<a class="headerlink" href="#batch-size-1" title="Permalink to this headline">¶</a></h3>
<p>Neural networks are often trained in batches of images, since the entire dataset is too large to read into memory at once. The size of these batches effects both the speed of training (larger batches train faster) and the stability of training (larger batches lead to more consistent results). The default batch_size of 1 is chosen because it is not possible to anticipate the available memory. Increase where possible. Typically batch sizes are evenly divisible by the size of the entire dataset.</p>
<p>** Note on batch_size: If using <code class="docutils literal notranslate"><span class="pre">multi-gpu</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>, batch_size refers to the total number of samples across all GPUs. For example, a <code class="docutils literal notranslate"><span class="pre">batch_size:</span> <span class="pre">18</span></code> for <code class="docutils literal notranslate"><span class="pre">multi-gpu:</span> <span class="pre">3</span></code> would produces 3 batches of 6 images, one set for each GPU. batch_size must therefore be larger than <code class="docutils literal notranslate"><span class="pre">multi-gpu</span></code> and evenly divisible.</p>
</div>
<div class="section" id="weights-none">
<h3>weights: None<a class="headerlink" href="#weights-none" title="Permalink to this headline">¶</a></h3>
<p>Neural networks consist of a set of matrix weights that are updated during model training. Starting from scratch with randomly initialized weights can significantly slow down training and decrease model performance. The <code class="docutils literal notranslate"><span class="pre">weights:</span></code> parameter allows you to start from previously saved weights, either from prebuilt models or from a custom session.</p>
<p>Saving example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
<div class="section" id="backbone-resnet50">
<h3>backbone: resnet50<a class="headerlink" href="#backbone-resnet50" title="Permalink to this headline">¶</a></h3>
<p>This is the keras retinanet backbone documented:</p>
<p>DeepForest has only been tested on resnet50 backbone.</p>
</div>
<div class="section" id="image-min-side-800">
<h3>image-min-side: 800<a class="headerlink" href="#image-min-side-800" title="Permalink to this headline">¶</a></h3>
<p>Object detection algorithms, such as retinanets, work by specifying anchor boxes to predict objects. This means that the scale and size of boxes should be consistent between training and prediction. To ensure that the bounding boxes fit the image, all images are resized before training and prediction. For example, <code class="docutils literal notranslate"><span class="pre">image-min-side:</span> <span class="pre">800</span></code> means that the smallest input image side would be resized to 800 pixels. This is a sensitive parameter and one that may need evaluation when training new data. Images that are too small will miss small trees, such they are outside the expected box size. Images that are too big will not fit in memory.</p>
</div>
<div class="section" id="multi-gpu-1">
<h3>multi-gpu: 1<a class="headerlink" href="#multi-gpu-1" title="Permalink to this headline">¶</a></h3>
<p>Number of GPUs to run. Ignored if running on CPU, which is automatically detected by tensorflow. As multi-gpu increases, pay close attention to the batch_size, which must be evenly divisible and greater or equal to the number of GPUs. Multi-gpu will yield significant training gains for very large training datasets. See training.md##-Training Hardware for more discussion.</p>
</div>
<div class="section" id="epochs-1">
<h3>epochs: 1<a class="headerlink" href="#epochs-1" title="Permalink to this headline">¶</a></h3>
<p>Number of times to show each image during training. At the end of an epoch, model checkpoint will save current weights if <code class="docutils literal notranslate"><span class="pre">save-snapshot:</span> <span class="pre">True</span></code>. It is difficult to anticipate a default setting form epochs, which will vary heavily on whether model is being trained from scratch (more epochs), is very similar to target prediction data (more epochs) or is likely to overfit (fewer epochs).</p>
</div>
<div class="section" id="freeze-layers-0">
<h3>freeze_layers: 0<a class="headerlink" href="#freeze-layers-0" title="Permalink to this headline">¶</a></h3>
<p>Current deprecated. Option to freeze a portion of convolutional layers of the model supplied in the <code class="docutils literal notranslate"><span class="pre">weights:</span></code> parameter.</p>
</div>
<div class="section" id="freeze-resnet-false">
<h3>freeze_resnet: False<a class="headerlink" href="#freeze-resnet-false" title="Permalink to this headline">¶</a></h3>
<p>Whether to allow training on the resnet background. Advanced feature for fine-tuning. If the target evaluation data is similar to the data in the <code class="docutils literal notranslate"><span class="pre">weights:</span> <span class="pre">&lt;path_to_file.h5&gt;</span></code>, option to turn off classifiction training. Learn more about <a class="reference external" href="https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html">finetuning</a>, and the <a class="reference external" href="https://towardsdatascience.com/object-detection-on-aerial-imagery-using-retinanet-626130ba2203">retinanet architecture</a></p>
</div>
<div class="section" id="score-threshold-0-05">
<h3>score_threshold: 0.05<a class="headerlink" href="#score-threshold-0-05" title="Permalink to this headline">¶</a></h3>
<p>Each bounding box comes with a probability score. Higher scores equates to more confidence in the bounding box label and extent. The <code class="docutils literal notranslate"><span class="pre">score_threshold</span></code> instructs keras-retinanet to ignore boxes below the threshold during model evaluation. For trees, we have found that these scores tend to be quite low compared to more conventional cases.</p>
</div>
</div>
<div class="section" id="keras-fit-generator-methods">
<h2>Keras fit_generator methods<a class="headerlink" href="#keras-fit-generator-methods" title="Permalink to this headline">¶</a></h2>
<p>These methods are not often changed unless experimenting with increasing training speed.</p>
<div class="section" id="multiprocessing-false">
<h3>multiprocessing: False<a class="headerlink" href="#multiprocessing-false" title="Permalink to this headline">¶</a></h3>
<p>Turn multiprocessing on (True) or off (False) during keras fit_generator methods. See</p>
<p>[https://keras.io/models/sequential/#fit_generator]</p>
</div>
<div class="section" id="workers-1">
<h3>workers: 1<a class="headerlink" href="#workers-1" title="Permalink to this headline">¶</a></h3>
<p>Number of parallel workers in fit_generator</p>
<p>[https://keras.io/models/sequential/#fit_generator]</p>
</div>
<div class="section" id="max-queue-size-10">
<h3>max_queue_size: 10<a class="headerlink" href="#max-queue-size-10" title="Permalink to this headline">¶</a></h3>
<p>Number of images to queue in fit_generator</p>
<p>[https://keras.io/models/sequential/#fit_generator]</p>
</div>
<div class="section" id="random-transform-true">
<h3>random_transform: True<a class="headerlink" href="#random-transform-true" title="Permalink to this headline">¶</a></h3>
<p>Data augmentations following keras-retinanet. In the fit_generator method, each annotation can be augmented. May be useful for small datasets.</p>
<p>See <a class="reference external" href="https://github.com/fizyr/keras-retinanet/blob/5524619f91699732ba24c6f52fb9e4b0b780b019/keras_retinanet/utils/transform.py#L27">the retinanet repo</a> for source of transformations.</p>
</div>
</div>
<div class="section" id="validation">
<h2>Validation<a class="headerlink" href="#validation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="validation-annotations-none">
<h3>validation_annotations: None<a class="headerlink" href="#validation-annotations-none" title="Permalink to this headline">¶</a></h3>
<p>At the end of each epoch, DeepForest can evaluate a file of annotations and return the mean average precision. <code class="docutils literal notranslate"><span class="pre">validation_annotations:</span> <span class="pre">&lt;path_to_file.h5&gt;</span></code> should point to a headerless .csv file in the following format</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image_path</span><span class="p">,</span> <span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
<p>For more information on formatting data see training.md##-Gather-annotations</p>
</div>
<div class="section" id="save-snapshot-false">
<h3>save-snapshot: False<a class="headerlink" href="#save-snapshot-false" title="Permalink to this headline">¶</a></h3>
<p>Whether to save a snapshot of model weights at the end of each epoch. This is useful for restarting training or saving a prediction model.</p>
<p>see [https://keras.io/callbacks/#ModelCheckpoint]</p>
</div>
<div class="section" id="save-path-snapshots">
<h3>save_path: snapshots/<a class="headerlink" href="#save-path-snapshots" title="Permalink to this headline">¶</a></h3>
<p>Path on disk to save images if validation_annotations is not <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
</div>
<div class="section" id="snapshot-path-snapshots">
<h3>snapshot_path: snapshots/<a class="headerlink" href="#snapshot-path-snapshots" title="Permalink to this headline">¶</a></h3>
<p>Path on disk to save snapshots if <code class="docutils literal notranslate"><span class="pre">save-snapshot:</span> <span class="pre">True</span></code></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="source/deepforest.html" class="btn btn-neutral float-right" title="deepforest package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="training.html" class="btn btn-neutral float-left" title="Training New Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Ben Weinstein

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>